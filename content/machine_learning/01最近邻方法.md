---
title: "懒惰学习：最近邻方法"
date: 2019-09-23T11:01:03+08:00
draft: false
---

> 机器学习与优化读书笔记


## 最近邻方法
在机器学习领域，最近邻方法的基本形式与基于实例的学习、基于案例的学习和基于记忆的学习有关。它的工作原理如下：我们把已标记的实例（包括输入及相应的输出的标记）储存起来，不进行任何操作，直到一个新输入模式需要一个输出。这种系统被称为**懒惰的学习者**：它们只是将这些实例储存起来，其他的什么也不做，直到用户询问它们。当一个新输入模式到达时，我们在存储器中查找到与这个新模式相近的那些实例，输出则由这些相近模式的输出所决定。
![最近邻分类](/machine_learning/2-3lazystudy.png)
这种方式一个缺陷就是：为识别一个新实例所花费的时间可能与存储器中的实例数量成正比。 \\
一个更具健壮性和灵活性的方法是考虑大小为 k 的近邻集合，而不仅仅是最相近的那一个，这种方法被称为**K 近邻（ KNN ）方法**。
这 k 个实例到新实例的距离可能有所差别，而且在某些情况下，距离较近的实例对新实例的输出影响更大是很合理的。在这种被称为加权**K 近邻（ WKNN ）的方法**中，权重取决于距离。
(1) 在训练集中找到 k 个下标 i 1 ,··· ,i k ，使得属性向量 x i 1 ,··· ,x i k 与给定的 x 最相近（根据某种给定的属性空间度量）。
(2) 通过下面的加权平均来计算估计的输出，权重反比于属性向量之间的距离：
![KNN公式](/machine_learning/2-3lazystudygongshi.png)
其中 d(x i ,x) 指两个向量在属性空间中的距离（例如欧氏距离）， d 0 是一个小的偏移常数，用以避免出现 0 作为除数的情况。 d 0 越大，距离较远的点的贡献就越大。如果 d 0 趋近于无穷大，那么这 k 个实例的权重就几乎一样了。

