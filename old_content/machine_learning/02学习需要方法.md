---
title: "学习需要方法"
date: 2019-09-23T11:48:41+08:00
draft: true
---

> 《机器学习与优化读书笔记》

通常我们会考虑两类问题:

**分类问题**（识别以特征 x 描述的某一特定目标的类别）中，输出是类别的相应编码。输
出 y 属于一个有限集，例如 y i = ±1 ，或者 y i ∈ {1,··· ,N} 。例如，可以将蘑菇分为两类：可
食用的和有毒的。
**回归问题**的输出从一开始就是一个实数值，它的目标是通过建模研究因变量（输出值 y ）
与一个或多个自变量（输入值 x ）之间的关系。例如，根据蘑菇的特征来预测其有毒物质的
含量。

---

## 从已标记的案例中学习：最小化和泛化
监督学习方法使用实例构造一个函数 y =f(x) ，将输入 x 和输出 y 关联起来。这一关联选自一个灵活的模型f(x;w) ，其中的灵活性来自**可调整的参数**（即**权重系数**） w 。
![最近邻分类](/machine_learning/3-1.png)
在许多情况下，特征提取需要一些来自人类的洞见，然而**最优参数的确定**则是完全自动的，这也是这一方法被称为机器学习的原因。让**模型**对训练集中的实例进行正确的分析，从而确定那些自由参数。

认为优化具有强大力量的真正信徒会先从定义**误差度量**（ error measure ）最小化开始并通过合适的（自动化的）优化过程来确定最优参数。这里的误差度量指所有正确答案（由实例的标记得出）与模型输出（由这个多功能盒子的输出得出）之间误差的总和。通常这个误差是一个绝对值，并经常取其平方值。“误差平方和”可能是机器学习领域应用最为广泛的一种误差度量。如果误差为零，表明这一模型在给定的实例上能百分之百地正确工作。误差越小，模型在这些实例上的平均表现就越好。

监督学习因此变成了最小化某个特定的误差函数，这一误差函数依赖于参数 w 。如果只关心最终结果，你可以把优化部分当作多功能盒子上的红色大按钮，当你将已标记的实例集输入这个盒子后，按下这个按钮，它会就某个具体问题提供自定义的结果。

如果你有兴趣开发新的 LION 工具，接下来的章节将为你呈现优化技术的更多细节。它们的要领是，如果函数是光滑的（想象一下宜人的草木丰茂的加州群山），人们可以蒙住眼睛，像跳伞那样找到一个随机初始点，然后用脚来感觉周围的地势，并总是向着最速下降的方向移动，这样就可以找到海拔很低的那些点（如湖泊）。计算机并未配备“人类视觉”来“看到”这些湖泊，只能每次抽样一个点。通过重复两个步骤，在当前点的邻域进行抽样 —— 在 w 空间中 —— 并移动到误差更小的邻居，可以生成一个值越来越小的轨迹。神奇的是，对许多应用而言，这个简单的过程足以达到适当的w值。

现在用数学的语言来表述。如果需要优化的函数是**可微的**，一个简单的方法是使用**梯度下降**（ gradient descent ）。人们可以重复地计算这个函数关于权重的梯度，并朝着负梯度的方向移动一小步。事实上，这是神经网络里很流行的一种技术，称为基于误差**反向传播**（ backpropagation ）的学习。

函数是平滑的，这一假设并非凭空捏造，而是基于监督学习的一个基础的平滑假设：若两个输入  距离很近，则它们对应的输出应该也很相近。如果这一假设不成立，那么就不可能将有限训练集泛化到可能无限多的尚未见过的新测试案例上。可以注意到，人们大脑中的信号和相互作用的物理现实都满足这一平滑假设。树突中的化学和电信号交互可看作神经元的输入，神经元的活动（输出）平滑地依赖这些输入，并依次作出反应。

到现在，你可能会认为机器学习等同于对训练集上的某性能度量的优化，但还缺失了一个部件。误差函数的最小化是首要的关键因素，但并不是唯一的。如果模型复杂度（灵活性、需要调整的参数个数）极高，模型在训练实例上达到零误差是非常容易的，但若将这个模型用于预测新实例的输出，则很可能会一塌糊涂。用人类的学习来打比方，如果死记硬背却未抓住真正的规律，学生将很难做到举一反三。这与偏差 – 方差（ bias-variance ）困境有关，它要求我们在选择模型的时候倍加小心，或者将目标函数最小化，改为训练实例误差与模型复杂度的加权组合。


**偏差 – 方差困境**可表述如下

- 参数过少的模型会因较大的偏差而失准：它们缺乏灵活性。
- 参数过多的模型则会因较大的方差而失准：它们对于样本中的细节过于敏感（细节中
的改变将会使模型产生大的变化）。
- 找到最佳模型需要控制“模型复杂度”，即模型的结构和参数数量都要恰到好处，从而
在偏差和方差之间达成折中方案。

避免过于复杂的模型，而优先选用简单的模型，这种偏好有一个有趣的名字：奥卡姆剃刀，意指“剃去”理论中那些不必要的复杂性。优化仍在使用，但由于顾及模型的复杂度问题，误差度量需要进行整合。